// http - 安全层 - tcp
// 安全层 有两个主要职责： 对发起http请求的数据进行加密操作 和 对接收到http的内容进行解密操作

加密方法

// 对称加密： 加密和解密都是用相同的密钥
// 1.浏览器发送它所支持的加密套件列表和一个随机数client-random
// 2.服务器会从加密套件列表选取一个加密套件，然后会生成一个service-random 并将service-random 和 加密套件列表返回给浏览器
// 最后浏览器和服务器分别返回确认消息  浏览器和服务端拥有了相同的client-random 和 serveice-random
//  使用相同方法将clinet-random 和 service-random 混合起来生成一个密钥 master secret 有了master secret 和 加密套件 双方就可以进行数据的加密传输了

// 缺点： client-random 和 service-random 的过程是明文的 意味着黑客也可以拿到协商的加密套件和双方的随机数 由于利用随机数合成密钥的算法是公开的 所以黑客拿到随机数之后 也可以合成密钥

使用非对称加密
// 非对称加密算法有a,b两把密钥， 如果你用a密钥来机密 那么只能使用b密钥来解密 反过来 如果你要用b密钥加密 那么只能用a密钥来解密

// 1 浏览器发送加密套件列表给服务器
// 2 服务器会选择一个加密套件 不过和对称加密不同的是 使用非对称加密时服务器上需要有用于浏览器加密的公钥和服务器解密http数据的私钥
// 由于公钥是给浏览器加密使用的 因此服务器会将加密套件和公钥一道发送给浏览器
// 3 最后就是浏览器和服务器返回确认信息

// 缺点 非对称加密的效率太低 无法保证服务器发送给浏览器的数据安全

对称加密和非对称加密搭配使用

// 传输数据阶段依然使用对称加密 但是对称加密的密钥我们采用非对称加密来传输

// 1.浏览器想服务器发送对称加密套件列表 非对称加密套件列表和随机数 client-random
// 2 服务器保存clinet-random 选择对称加密和非对称加密的套件 然后生成随机数service-random 向浏览器发送选择的加密套件 service-random和公钥
// 3 浏览器保存公钥 并生成随机数pre-master 然后利用公钥 pre-master 加密 并向服务器发送加密后的数据
// 4 最后服务器拿出自己的私钥 解密出pre-master 数据 并返回确认信息
// 服务器和浏览器就有了共同的clinet-random 和 service-random 和 pre-master 然后服务器和浏览器会使用这三组随机数生成对称密钥 因为服务器和浏览器使用同一套方法来生成密钥 所以最终生成的密钥也是相同的

// pre-master 是经过公钥加密后传输的 黑客无法获取到pre-master

// 以上方法都有点弱 黑客还是可以通过dns劫持 将你的地址替换成黑客的地址 黑客的地址就可以获得公钥和私钥 去搞你 所以就有了ca证书
// ca 一个是通过数字证书向浏览器证明服务器的身份 另一个是数字证书里面包含了服务器的公钥
// // 相比第三版https协议
// 1. 服务器没有直接返回公钥给浏览器 而是返回了数字证书 而公钥正是包含在数字证书中的
// 2. 在浏览器端多了一个证书验证操作 验证了证书之后 才继续后续流程

// xss 存储型xss攻击 反射型xss攻击 和 基于dom的xss攻击
// 和 XSS 不同的是，CSRF 攻击不需要将恶意代码注入用户的页面，仅仅是利用服务器的漏洞和用户的登录状态来实施攻击

// http0.9 非常简陋 为了后面支持的多样性 发展除了http1.0(提供了对多文件的良好支持)
// http1.0 每进行一次http通信 都要经历tcp链接 传输http数据和断开tcp链接三个阶段 这样在面对页面的图片文件越来越多 有时候一个页面包含了几百个外部引用的资源文件
// 如果下载每个文件的时候 都要经历tcp链接 传输数据 和断开联接 这样的步骤 无疑会增加大量无谓的开销

// http1.1 增加了持久链接的方法 它的特点是在一个tcp链接上 可以传输多个http请求 只要浏览器或者服务器没有明确断开链接 那么改tcp链接会一直保持
// http1.1 中国默认开启持久链接 如果不想采用持久链接 在http请求头加上connection：close 浏览器对同一个域名默认允许同时建立6个tcp持久链接

// http持久链接 虽然可以减少tcp的建立和断开次数 但是需要等待前面的请求返回之后 才能进行下一次的请求 如果tcp通道中的某个请求因为某些原因没有及时返回就会阻赛后面所有的请求 队头阻赛

// http1.1 增加了持久链接 浏览器为每个域名最多同时维护6各tcp持久链接 使用cdn的实现域名分片机制

// http1.1的主要问题： 对带宽利用率不理想  原因 1tcp的慢启动 2 同时开启了多条tcp连接  连接会竞争固定的带宽 3.队头阻赛

// http2 多路复用 ---》http3还没有广泛适用浏览器 + quic协议
